LLMSettings=LLM-based test generation settings
llmToken=Enter your LLM platform token
parametersDepth=The depth of input parameters used in class under tests
maximumNumberOfRequests=Maximum number of requests to LLM
maximumPolyDepth=Maximum polymorphism depth
preferredJUnitVersion=Preferred JUnit version in case of the same priority
model=Model used for the chat completion
llmPlatform=LLM platform
PromptSeparator=Prompt Editor
defaultLLMRequestsSeparator=Default LLM Requests
provideTestSamplesCheckBox=Provide test samples for LLM
llmSetupCheckBox=Setup LLM settings during the generation
junitVersionPriorityCheckBox=Detected in the project JUnit versions always have higher priority over undetected ones
junitVersion=JUnit version
selectPrompt=Select the prompt: